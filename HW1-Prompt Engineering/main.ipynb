{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-generativeai langchain langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å–®ç´”ä¸² Gemini 1.5 API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import google.generativeai as genai\n",
    "\n",
    "API_KEY = \"AIzaSyDAI6yk07b0ocssMsy4o2AM3RdSWnHqf_M\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "sample_df = pd.read_csv(\"mmlu_sample.csv\", sep=\",\")  # è¨“ç·´é›†\n",
    "submit_df = pd.read_csv(\"mmlu_submit.csv\", sep=\",\")  # æ¸¬è©¦é›†\n",
    "submit_format_df = pd.read_csv(\"submit_format.csv\")  # åƒè€ƒè¼¸å‡ºæ ¼å¼\n",
    "\n",
    "# ç”¢ç”Ÿ LLM è¨“ç·´ Promptï¼ˆä»¥ mmlu_sample.csv ä½œç‚º few-shot learningï¼‰\n",
    "few_shot_count = 10\n",
    "few_shot_examples = sample_df.sample(few_shot_count, random_state=42)\n",
    "\n",
    "training_examples = []\n",
    "for _, row in few_shot_examples.iterrows():\n",
    "    reasoning_text = (\n",
    "        \"Carefully analyze the question, the choices, \"\n",
    "        \"and provide a concise reasoning process to arrive at the correct answer. \"\n",
    "        f\"In this case, the correct answer is {row['target']}.\"\n",
    "    )\n",
    "\n",
    "    example = f\"\"\"\n",
    "You are a helpful AI assistant using zero-shot CoT reasoning. \n",
    "When you solve the following multiple-choice question, silently reason through the problem, \n",
    "but provide a brief justification (few-shot style). \n",
    "DO NOT reveal your entire chain-of-thought.\n",
    "\n",
    "Question: {row['input']}\n",
    "A: {row['A']}\n",
    "B: {row['B']}\n",
    "C: {row['C']}\n",
    "D: {row['D']}\n",
    "\n",
    "Reasoning: {reasoning_text}\n",
    "\n",
    "Correct Answer: {row['target']}\n",
    "\n",
    "DO NOT reply instantlyâ€“ if you have any questions about this prompt, ask me.\n",
    "\"\"\".strip()\n",
    "\n",
    "    training_examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "training_prompt = \"\\n\\n\".join(training_examples)\n",
    "\n",
    "predictions = []\n",
    "count_requests = 0  \n",
    "daily_limit = 1500\n",
    "\n",
    "for _, row in submit_df.iterrows():\n",
    "    question_prompt = f\"\"\"\n",
    "You are a helpful AI assistant. Below are examples of how to answer multiple-choice questions with a short reasoning process \n",
    "(few-shot prompts, zero-shot CoT):\n",
    "\n",
    "{training_prompt}\n",
    "\n",
    "Instructions:\n",
    "1. Carefully analyze the question and each answer choice.\n",
    "2. Silently reason through the steps (zero-shot CoT), but provide only a brief final reasoning explanation.\n",
    "3. Output your final answer in the exact format:\n",
    "   Correct answer: X\n",
    "   (Where X is A, B, C, or D)\n",
    "4. DO NOT reply instantly â€“ if you have any questions about this prompt, ask me.\n",
    "\n",
    "Question: {row['input']}\n",
    "A: {row['A']}\n",
    "B: {row['B']}\n",
    "C: {row['C']}\n",
    "D: {row['D']}\n",
    "\"\"\".strip()\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "    response = model.generate_content(\n",
    "        question_prompt,\n",
    "        generation_config={\n",
    "            \"temperature\": 0.8,\n",
    "            \"top_p\": 0.9,\n",
    "            \"presence_penalty\": 0.1,\n",
    "            \"frequency_penalty\": 0.1\n",
    "        }\n",
    "    )\n",
    "\n",
    "    raw_answer = response.text.strip()\n",
    "    \n",
    "    if \"Correct answer:\" in raw_answer:\n",
    "        # åˆ†å‰²å¾Œï¼Œå–å†’è™Ÿå¾Œçš„ç¬¬ä¸€å€‹å­—æ¯\n",
    "        answer_part = raw_answer.split(\"Correct answer:\")[-1].strip()\n",
    "        predicted_option = answer_part[0].upper()  # å–A/B/C/D\n",
    "        if predicted_option not in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            predicted_option = \"A\" \n",
    "    else:\n",
    "        predicted_option = \"A\"\n",
    "    \n",
    "    predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "    \n",
    "    count_requests += 1\n",
    "    time.sleep(4) \n",
    "    \n",
    "    if count_requests >= daily_limit:\n",
    "        print(f\"Reached the daily limit of {daily_limit} requests. Stopping...\")\n",
    "        break\n",
    "\n",
    "output_df = pd.DataFrame(predictions)\n",
    "output_df.to_csv(\"submit_format.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to submit_format.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ©ç”¨ Langchain ä¸­çš„ Gemini 2.0 + CoT + å‹•æ…‹æŒ‘é¸ few-shot é¡Œç›®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDAI6yk07b0ocssMsy4o2AM3RdSWnHqf_M\"\n",
    "\n",
    "sample_df = pd.read_csv(\"mmlu_sample.csv\", sep=\",\")  # è¨“ç·´é›†\n",
    "submit_df = pd.read_csv(\"mmlu_submit.csv\", sep=\",\")  # æ¸¬è©¦é›†\n",
    "\n",
    "few_shot_count = 5\n",
    "\n",
    "# å®šç¾©é¡Œç›®é¡žåž‹ç‰¹å®šçš„ç­–ç•¥\n",
    "category_strategies = {\n",
    "    \"high_school_biology\": \"Focus on biological concepts, terminology, and processes.\",\n",
    "    \"high_school_computer_science\": \"Analyze logic, algorithms, and programming principles.\",\n",
    "    \"high_school_european_history\": \"Consider historical context, timelines, and cause-effect relationships.\",\n",
    "    \"high_school_geography\": \"Focus on spatial relationships, physical features, and human-environment interactions.\",\n",
    "    \"high_school_government_and_politics\": \"Evaluate political systems, institutions, and principles.\",\n",
    "    \"high_school_macroeconomics\": \"Analyze economic principles, markets, and policies.\",\n",
    "    \"high_school_microeconomics\": \"Focus on individual markets, supply-demand, and decision-making.\",\n",
    "    \"high_school_psychology\": \"Consider human behavior, mental processes, and psychological theories.\",\n",
    "    \"high_school_us_history\": \"Examine key events, figures, and developments in U.S. history.\",\n",
    "    \"high_school_world_history\": \"Evaluate global events, cultures, and historical trends.\"\n",
    "}\n",
    "\n",
    "role_dict = {\n",
    "    \"high_school_biology\": \"a high school biology teacher\",\n",
    "    \"high_school_computer_science\": \"a computer science professor\",\n",
    "    \"high_school_european_history\": \"a European history expert\",\n",
    "    \"high_school_geography\": \"a geography educator\",\n",
    "    \"high_school_government_and_politics\": \"a political science scholar\",\n",
    "    \"high_school_macroeconomics\": \"an economics professor specializing in macroeconomics\",\n",
    "    \"high_school_microeconomics\": \"an economics professor specializing in microeconomics\",\n",
    "    \"high_school_psychology\": \"a psychology instructor\",\n",
    "    \"high_school_us_history\": \"a U.S. history expert\",\n",
    "    \"high_school_world_history\": \"a world history specialist\"\n",
    "}\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are {role} specializing in solving multiple-choice questions with high accuracy. The current question is from {task}.\n",
    "\n",
    "ðŸ”¹ **Rules**:\n",
    "1. Output only the final answer in this exact format: 'Correct answer: X' (where X is A, B, C, or D).\n",
    "2. Do NOT include reasoning, justifications, or additional text in your output.\n",
    "3. Think step-by-step internally:\n",
    "   - Identify the key concepts or facts in the question.\n",
    "   - Evaluate each option based on those concepts.\n",
    "   - Eliminate incorrect options systematically.\n",
    "   - Internally, imagine explaining the answer to a student, considering each option carefully.\n",
    "4. Use these strategies for {task} questions: {task_strategy}.\n",
    "5. For each option, consider why it might be correct or incorrect, and compare it to the others.\n",
    "6. Double-check your conclusion by revisiting the question and options to ensure accuracy.\n",
    "\n",
    "ðŸ“Œ **Examples:**\n",
    "{few_shot}\n",
    "\n",
    "Now solve this question:\n",
    "\n",
    "Question: {question}\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\"\"\",\n",
    "    input_variables=[\"role\", \"task\", \"task_strategy\", \"few_shot\", \"question\", \"A\", \"B\", \"C\", \"D\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)  \n",
    "chain = prompt_template | llm \n",
    "output_parser = RegexParser(regex=r\"Correct answer: ([A-D])\", output_keys=[\"target\"])\n",
    "\n",
    "# å‡½æ•¸ æå–ç­”æ¡ˆ\n",
    "def extract_answer(response):\n",
    "    patterns = [\n",
    "        r\"Correct answer:\\s*([A-D])\",\n",
    "        r\"Answer:\\s*([A-D])\",\n",
    "        r\"The correct option is\\s*([A-D])\",\n",
    "        r\"I choose\\s*([A-D])\",\n",
    "        r\"Final answer:\\s*([A-D])\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, response, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).upper()\n",
    "    lines = response.strip().split('\\n')\n",
    "    last_line = lines[-1].strip()\n",
    "    match = re.search(r\"[A-D]\", last_line)\n",
    "    if match:\n",
    "        return match.group(0).upper()\n",
    "    return random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "predictions = []\n",
    "errors = []\n",
    "count_requests = 0\n",
    "daily_limit = 1500\n",
    "\n",
    "for _, row in submit_df.iterrows():\n",
    "    # æ ¹æ“šç•¶å‰é¡Œç›®çš„ task å‹•æ…‹æŒ‘é¸ Few-shot ç¯„ä¾‹\n",
    "    task = row[\"task\"]\n",
    "    task_examples = sample_df[sample_df[\"task\"] == task]\n",
    "    few_shot_examples = task_examples.sample(min(few_shot_count, len(task_examples)), random_state=42)\n",
    "    few_shot_text = \"\\n\".join([\n",
    "        f\"\"\"Example {i+1}:\n",
    "Question: {ex['input']}\n",
    "A) {ex['A']}\n",
    "B) {ex['B']}\n",
    "C) {ex['C']}\n",
    "D) {ex['D']}\n",
    "Correct Answer: {ex['target']}\"\"\" for i, (_, ex) in enumerate(few_shot_examples.iterrows())\n",
    "    ])\n",
    "\n",
    "    # å‹•æ…‹é¸æ“‡ task å°æ‡‰çš„ç­–ç•¥å’Œè§’è‰²\n",
    "    task_strategy = category_strategies.get(task, \"Use general knowledge and logical reasoning.\")\n",
    "    role = role_dict.get(task, \"an expert in general knowledge\")\n",
    "\n",
    "    question_data = {\n",
    "        \"role\": role,\n",
    "        \"task\": task,\n",
    "        \"task_strategy\": task_strategy,\n",
    "        \"few_shot\": few_shot_text,\n",
    "        \"question\": row[\"input\"],\n",
    "        \"A\": row[\"A\"],\n",
    "        \"B\": row[\"B\"],\n",
    "        \"C\": row[\"C\"],\n",
    "        \"D\": row[\"D\"]\n",
    "    }\n",
    "\n",
    "    # å‘¼å« LLM ç”¢ç”Ÿå›žç­”\n",
    "    response = chain.invoke(question_data).content\n",
    "    # æå–ç­”æ¡ˆ\n",
    "    predicted_option = extract_answer(response)\n",
    "    \n",
    "    if predicted_option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "    else:\n",
    "        predicted_option = random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
    "        errors.append({\n",
    "            \"ID\": row[\"Unnamed: 0\"],\n",
    "            \"input\": row[\"input\"],\n",
    "            \"response\": response,\n",
    "            \"reason\": \"ç„¡æ³•è§£æž\"\n",
    "        })\n",
    "        predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "    \n",
    "    count_requests += 1\n",
    "    time.sleep(4)\n",
    "    \n",
    "    if count_requests >= daily_limit:\n",
    "        print(f\"Reached the daily limit of {daily_limit} requests. Stopping...\")\n",
    "        break\n",
    "\n",
    "output_df = pd.DataFrame(predictions)\n",
    "output_df.to_csv(\"submit_format.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to submit_format.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ”¹é€²ç‰ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import RegexParser\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# è¨­ç½® Google API Key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDAI6yk07b0ocssMsy4o2AM3RdSWnHqf_M\"\n",
    "\n",
    "# è®€å– CSV æª”æ¡ˆ\n",
    "sample_df = pd.read_csv(\"mmlu_sample.csv\", sep=\",\")  # è¨“ç·´é›†\n",
    "submit_df = pd.read_csv(\"mmlu_submit.csv\", sep=\",\")  # æ¸¬è©¦é›†\n",
    "\n",
    "# Few-shot ç¯„ä¾‹æ•¸é‡\n",
    "few_shot_count = 5\n",
    "\n",
    "# å®šç¾©é¡Œç›®é¡žåž‹ç‰¹å®šçš„ç­–ç•¥\n",
    "category_strategies = {\n",
    "    \"high_school_biology\": \"Delve into fundamental biological concepts, technical terminology, and biological processes.\",\n",
    "    \"high_school_computer_science\": \"Analyze programming logic, algorithms, and principles of software design.\",\n",
    "    \"high_school_european_history\": \"Examine European historical contexts, key events, and their cause-effect relationships.\",\n",
    "    \"high_school_geography\": \"Focus on spatial distributions, natural landforms, and human-environment interactions.\",\n",
    "    \"high_school_government_and_politics\": \"Evaluate political systems, governmental operations, and core political theories.\",\n",
    "    \"high_school_macroeconomics\": \"Explore macroeconomic principles, market dynamics, and the impact of policies.\",\n",
    "    \"high_school_microeconomics\": \"Concentrate on individual markets, supply-demand interactions, and consumer behavior.\",\n",
    "    \"high_school_psychology\": \"Study psychological theories, behavioral patterns, and cognitive processes.\",\n",
    "    \"high_school_us_history\": \"Review significant events, figures, and developmental trends in U.S. history.\",\n",
    "    \"high_school_world_history\": \"Assess global historical trends, cultural exchanges, and international influences.\"\n",
    "}\n",
    "\n",
    "role_dict = {\n",
    "    \"high_school_biology\": \"a biology professor specializing in high school curricula\",\n",
    "    \"high_school_computer_science\": \"a computer science professor with expertise in programming logic\",\n",
    "    \"high_school_european_history\": \"a European history expert focused on high school education\",\n",
    "    \"high_school_geography\": \"a geography educator specializing in spatial analysis\",\n",
    "    \"high_school_government_and_politics\": \"a political science scholar with knowledge of governmental systems\",\n",
    "    \"high_school_macroeconomics\": \"a macroeconomics professor specializing in economic policy\",\n",
    "    \"high_school_microeconomics\": \"a microeconomics professor focused on market dynamics\",\n",
    "    \"high_school_psychology\": \"a psychology instructor with expertise in behavioral theories\",\n",
    "    \"high_school_us_history\": \"a U.S. history expert specializing in key events and trends\",\n",
    "    \"high_school_world_history\": \"a world history specialist focused on global trends\"\n",
    "}\n",
    "\n",
    "# å»ºç«‹å„ªåŒ–ç‰ˆ PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are {role} specializing in solving multiple-choice questions with high accuracy. The current question is from {task}.\n",
    "\n",
    "ðŸ”¹ **Rules**:\n",
    "1. Output only the final answer in this exact format: 'Correct answer: X' (where X is A, B, C, or D).\n",
    "2. Include only the output, avoiding reasoning or additional text.\n",
    "\n",
    "ðŸ”¹ **Instructions**:\n",
    "Solve the question by reasoning step-by-step:\n",
    "1. Identify the core concept or fact the question is testing.\n",
    "2. Analyze each option:\n",
    "   - Assess its alignment with the core concept.\n",
    "   - Note why it might be correct or incorrect.\n",
    "3. Eliminate incorrect options:\n",
    "   - Identify flaws (e.g., factual errors, misinterpretations).\n",
    "   - Watch for traps (e.g., subtle wording differences).\n",
    "4. Confirm the answer:\n",
    "   - Ensure the remaining option fully answers the question.\n",
    "\n",
    "ðŸ”¹ **Strategy**:\n",
    "Use these strategies for {task} questions: {task_strategy}.\n",
    "\n",
    "ðŸ“Œ **Examples**:\n",
    "{few_shot}\n",
    "\n",
    "Now solve this question:\n",
    "\n",
    "Question: {question}\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\"\"\",\n",
    "    input_variables=[\"role\", \"task\", \"task_strategy\", \"few_shot\", \"question\", \"A\", \"B\", \"C\", \"D\"]\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ– LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.1)  \n",
    "chain = prompt_template | llm \n",
    "output_parser = RegexParser(regex=r\"Correct answer: ([A-D])\", output_keys=[\"target\"])\n",
    "\n",
    "# å®šç¾©ä¸€å€‹å‡½æ•¸ä¾†æå–ç­”æ¡ˆ\n",
    "def extract_answer(response):\n",
    "    patterns = [\n",
    "        r\"Correct answer:\\s*([A-D])\",\n",
    "        r\"Answer:\\s*([A-D])\",\n",
    "        r\"The correct option is\\s*([A-D])\",\n",
    "        r\"I choose\\s*([A-D])\",\n",
    "        r\"Final answer:\\s*([A-D])\",\n",
    "        r\"Option\\s*([A-D])\\s*is correct\",\n",
    "        r\"The answer is\\s*([A-D])\",\n",
    "        r\"([A-D])\\s*is the correct choice\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, response, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).upper()\n",
    "    # æª¢æŸ¥æœ€å¾Œä¸€è¡Œæ˜¯å¦æœ‰é—œéµè©ž\n",
    "    last_line = response.split('\\n')[-1].strip()\n",
    "    match = re.search(r\"[A-D]\", last_line)\n",
    "    if match:\n",
    "        return match.group(0).upper()\n",
    "    # è‹¥ä»ç„¡åŒ¹é…ï¼Œéš¨æ©Ÿé¸æ“‡ï¼ˆä½†é€™æ˜¯æœ€å¾Œæ‰‹æ®µï¼‰\n",
    "    return random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "# def get_similar_examples(question, task_examples, n=4):   #TF-IDF\n",
    "#     vectorizer = TfidfVectorizer()\n",
    "#     task_texts = task_examples[\"input\"].tolist()\n",
    "#     all_texts = [question] + task_texts\n",
    "#     tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "#     similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])[0]\n",
    "#     top_indices = similarities.argsort()[-n:][::-1]\n",
    "#     return task_examples.iloc[top_indices]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')   #Sentence-BERT\n",
    "\n",
    "def get_similar_examples(question, task_examples, n=3):\n",
    "    question_embedding = model.encode(question)\n",
    "    example_embeddings = model.encode(task_examples[\"input\"].tolist())\n",
    "    similarities = util.pytorch_cos_sim(question_embedding, example_embeddings)[0]\n",
    "    top_indices = similarities.argsort(descending=True)[:n]\n",
    "    return task_examples.iloc[top_indices]\n",
    "\n",
    "# ä¸»ç¨‹å¼ç¢¼\n",
    "predictions = []\n",
    "errors = []\n",
    "count_requests = 0\n",
    "daily_limit = 1500\n",
    "\n",
    "for _, row in submit_df.iterrows():\n",
    "    # æ ¹æ“šç•¶å‰é¡Œç›®çš„ task å‹•æ…‹æŒ‘é¸ Few-shot ç¯„ä¾‹\n",
    "    task = row[\"task\"]\n",
    "    task_examples = sample_df[sample_df[\"task\"] == task]\n",
    "    similar_examples = get_similar_examples(row[\"input\"], task_examples, 3)\n",
    "    random_examples = task_examples.sample(min(2, len(task_examples)), random_state=42)\n",
    "    few_shot_examples = pd.concat([similar_examples, random_examples]).drop_duplicates()\n",
    "    # few_shot_examples = task_examples.sample(min(few_shot_count, len(task_examples)), random_state=42)\n",
    "    \n",
    "    few_shot_text = \"\\n\".join([\n",
    "        f\"\"\"Example {i+1}:\n",
    "Question: {ex['input']}\n",
    "A) {ex['A']}\n",
    "B) {ex['B']}\n",
    "C) {ex['C']}\n",
    "D) {ex['D']}\n",
    "Correct Answer: {ex['target']}\"\"\" for i, (_, ex) in enumerate(few_shot_examples.iterrows())\n",
    "    ])\n",
    "\n",
    "    # å‹•æ…‹é¸æ“‡ task å°æ‡‰çš„ç­–ç•¥å’Œè§’è‰²\n",
    "    task_strategy = category_strategies.get(\n",
    "        task,\n",
    "        \"Implement a comprehensive strategy that leverages detailed domain expertise and rigorous logical reasoning...\"\n",
    "    )\n",
    "    role = role_dict.get(task, \"a seasoned expert with extensive domain-specific knowledge\")\n",
    "\n",
    "    # æº–å‚™è¼¸å…¥æ•¸æ“š\n",
    "    question_data = {\n",
    "        \"role\": role,\n",
    "        \"task\": task,\n",
    "        \"task_strategy\": task_strategy,\n",
    "        \"few_shot\": few_shot_text,\n",
    "        \"question\": row[\"input\"],\n",
    "        \"A\": row[\"A\"],\n",
    "        \"B\": row[\"B\"],\n",
    "        \"C\": row[\"C\"],\n",
    "        \"D\": row[\"D\"]\n",
    "    }\n",
    "\n",
    "    # å‘¼å« LLM ç”¢ç”Ÿå›žç­”\n",
    "    response = chain.invoke(question_data).content\n",
    "    \n",
    "    # æå–ç­”æ¡ˆ\n",
    "    predicted_option = extract_answer(response)\n",
    "    \n",
    "    if predicted_option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "        predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "    else:\n",
    "        predicted_option = random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
    "        errors.append({\n",
    "            \"ID\": row[\"Unnamed: 0\"],\n",
    "            \"input\": row[\"input\"],\n",
    "            \"response\": response,\n",
    "            \"reason\": \"ç„¡æ³•è§£æžç­”æ¡ˆ\"\n",
    "        })\n",
    "        predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "    \n",
    "    count_requests += 1\n",
    "    time.sleep(4)\n",
    "    \n",
    "    if count_requests >= daily_limit:\n",
    "        print(f\"Reached the daily limit of {daily_limit} requests. Stopping...\")\n",
    "        break\n",
    "\n",
    "# å„²å­˜è¼¸å‡º\n",
    "output_df = pd.DataFrame(predictions)\n",
    "output_df.to_csv(\"submit_format.csv\", index=False)\n",
    "\n",
    "if errors:\n",
    "    error_df = pd.DataFrame(errors)\n",
    "    error_df.to_csv(\"errors.csv\", index=False)\n",
    "    print(f\"Some questions were incomplete or had issues. Check 'errors.csv' for details.\")\n",
    "\n",
    "print(\"Results saved to submit_format.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini-1.5-pro ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCWX4Zzt0Pe7269rkSgvVR4uOKxu2fuCvQ\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDAI6yk07b0ocssMsy4o2AM3RdSWnHqf_M\" \n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAX5JPYCBANYsHSx3-3W-aDq3_H3VQsKeM\" \n",
    "\n",
    "sample_df = pd.read_csv(\"mmlu_sample.csv\", sep=\",\")  # è¨“ç·´é›†\n",
    "submit_df = pd.read_csv(\"mmlu_submit.csv\", sep=\",\")  # æ¸¬è©¦é›†\n",
    "\n",
    "\n",
    "category_strategies = {\n",
    "    \"high_school_biology\": \"Focus on biological concepts, terminology, and processes.\",\n",
    "    \"high_school_computer_science\": \"Analyze logic, algorithms, and programming principles.\",\n",
    "    \"high_school_european_history\": \"Consider historical context, timelines, and cause-effect relationships.\",\n",
    "    \"high_school_geography\": \"Focus on spatial relationships, physical features, and human-environment interactions.\",\n",
    "    \"high_school_government_and_politics\": \"Evaluate political systems, institutions, and principles.\",\n",
    "    \"high_school_macroeconomics\": \"Analyze economic principles, markets, and policies.\",\n",
    "    \"high_school_microeconomics\": \"Focus on individual markets, supply-demand, and decision-making.\",\n",
    "    \"high_school_psychology\": \"Consider human behavior, mental processes, and psychological theories.\",\n",
    "    \"high_school_us_history\": \"Examine key events, figures, and developments in U.S. history.\",\n",
    "    \"high_school_world_history\": \"Evaluate global events, cultures, and historical trends.\"\n",
    "}\n",
    "\n",
    "role_dict = {\n",
    "    \"high_school_biology\": \"a high school biology teacher\",\n",
    "    \"high_school_computer_science\": \"a computer science professor\",\n",
    "    \"high_school_european_history\": \"a European history expert\",\n",
    "    \"high_school_geography\": \"a geography educator\",\n",
    "    \"high_school_government_and_politics\": \"a political science scholar\",\n",
    "    \"high_school_macroeconomics\": \"an economics professor specializing in macroeconomics\",\n",
    "    \"high_school_microeconomics\": \"an economics professor specializing in microeconomics\",\n",
    "    \"high_school_psychology\": \"a psychology instructor\",\n",
    "    \"high_school_us_history\": \"a U.S. history expert\",\n",
    "    \"high_school_world_history\": \"a world history specialist\"\n",
    "}\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are {role} specializing in solving multiple-choice questions with high accuracy. The current question is from {task}.\n",
    "\n",
    "ðŸ”¹ **Rules**:\n",
    "1. Output only the final answer in this exact format: 'Correct answer: X' (where X is A, B, C, or D).\n",
    "2. Do NOT include reasoning, justifications, or additional text in your output.\n",
    "3. Think step-by-step internally:\n",
    "   - Step 1: Identify the key topic or concept in the question.\n",
    "   - Step 2: Recall relevant facts, definitions, or principles related to {task}.\n",
    "   - Step 3: Evaluate each option by comparing it to the identified concepts.\n",
    "   - Step 4: Eliminate incorrect options based on inaccuracies or inconsistencies.\n",
    "   - Step 5: Double-check the remaining option(s) against the question to confirm accuracy.\n",
    "4. Use these strategies for {task} questions: {task_strategy}.\n",
    "5. Pay attention to subtle differences between options to avoid common pitfalls.\n",
    "6. Imagine explaining your choice to a student, ensuring every step is clear and logical.\n",
    "\n",
    "ðŸ“Œ **Examples:**\n",
    "{few_shot}\n",
    "\n",
    "Now solve this question:\n",
    "\n",
    "Question: {question}\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\"\"\",\n",
    "    input_variables=[\"role\", \"task\", \"task_strategy\", \"few_shot\", \"question\", \"A\", \"B\", \"C\", \"D\"]\n",
    ")\n",
    "\n",
    "def extract_answer(response):\n",
    "    patterns = [\n",
    "        r\"Correct answer:\\s*([A-D])\",\n",
    "        r\"Answer:\\s*([A-D])\",\n",
    "        r\"The correct option is\\s*([A-D])\",\n",
    "        r\"I choose\\s*([A-D])\",\n",
    "        r\"Final answer:\\s*([A-D])\"\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, response, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).upper()\n",
    "    lines = response.strip().split('\\n')\n",
    "    last_line = lines[-1].strip()\n",
    "    match = re.search(r\"[A-D]\", last_line)\n",
    "    if match:\n",
    "        return match.group(0).upper()\n",
    "    return random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "\n",
    "def get_similar_examples(current_question, task_examples, few_shot_count=5):\n",
    "    if len(task_examples) <= few_shot_count:\n",
    "        return task_examples  # å¦‚æžœç¯„ä¾‹æ•¸é‡ä¸è¶³ï¼Œç›´æŽ¥è¿”å›žæ‰€æœ‰ç¯„ä¾‹\n",
    "    \n",
    "    # ä½¿ç”¨ TF-IDF è¨ˆç®—ç›¸ä¼¼åº¦\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')  \n",
    "    current_text = current_question.lower()\n",
    "    example_texts = task_examples[\"input\"].str.lower().tolist()\n",
    "    tfidf_matrix = vectorizer.fit_transform([current_text] + example_texts)\n",
    "    similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    \n",
    "    top_indices = similarities.argsort()[-few_shot_count:][::-1]\n",
    "    return task_examples.iloc[top_indices]\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0.2,\n",
    "    max_output_tokens=50  \n",
    ")\n",
    "chain = prompt_template | llm \n",
    "output_parser = RegexParser(regex=r\"Correct answer: ([A-D])\", output_keys=[\"target\"])\n",
    "\n",
    "\n",
    "def process_batch(batch_data, predictions, errors):\n",
    "    batch_inputs = []\n",
    "    for row in batch_data:\n",
    "        task = row[\"task\"]\n",
    "        task_examples = sample_df[sample_df[\"task\"] == task]\n",
    "        few_shot_examples = get_similar_examples(row[\"input\"], task_examples, few_shot_count=3)\n",
    "        few_shot_text = \"\\n\".join([\n",
    "            f\"Example {i+1}:\\nQuestion: {ex['input']}\\nA) {ex['A']}\\nB) {ex['B']}\\nC) {ex['C']}\\nD) {ex['D']}\\nCorrect Answer: {ex['target']}\"\n",
    "            for i, (_, ex) in enumerate(few_shot_examples.iterrows())\n",
    "        ])\n",
    "        task_strategy = category_strategies.get(task, \"Use general knowledge and logical reasoning.\")\n",
    "        role = role_dict.get(task, \"an expert in general knowledge\")\n",
    "        \n",
    "        question_data = {\n",
    "            \"role\": role,\n",
    "            \"task\": task,\n",
    "            \"task_strategy\": task_strategy,\n",
    "            \"few_shot\": few_shot_text,\n",
    "            \"question\": row[\"input\"],\n",
    "            \"A\": row[\"A\"],\n",
    "            \"B\": row[\"B\"],\n",
    "            \"C\": row[\"C\"],\n",
    "            \"D\": row[\"D\"]\n",
    "        }\n",
    "        batch_inputs.append(question_data)\n",
    "\n",
    "    try:\n",
    "        responses = [chain.invoke(input_data).content for input_data in batch_inputs]\n",
    "        for row, response in zip(batch_data, responses):\n",
    "            predicted_option = extract_answer(response)\n",
    "            if predicted_option in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "                predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "            else:\n",
    "                predicted_option = random.choice([\"A\", \"B\", \"C\", \"D\"])\n",
    "                errors.append({\n",
    "                    \"ID\": row[\"Unnamed: 0\"],\n",
    "                    \"input\": row[\"input\"],\n",
    "                    \"response\": response,\n",
    "                    \"reason\": f\"Invalid answer format: {predicted_option}\"\n",
    "                })\n",
    "                predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": predicted_option})\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e).lower()\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦æ˜¯å› ç‚ºé…é¡ç”¨ç›¡\n",
    "        # å¦‚æžœæ˜¯ï¼Œå‰‡å„²å­˜ç•¶å‰é€²åº¦ä¸¦é€€å‡º\n",
    "        if \"quota\" in error_msg or \"exhausted\" in error_msg or \"limit\" in error_msg:\n",
    "            print(f\"Quota exhausted detected: {str(e)}\")\n",
    "            print(\"Saving current progress and exiting\")\n",
    "            output_df = pd.DataFrame(predictions)\n",
    "            output_df.to_csv(\"submit_format_partial.csv\", index=False)\n",
    "            if errors:\n",
    "                error_df = pd.DataFrame(errors)\n",
    "                error_df.to_csv(\"errors_partial.csv\", index=False)\n",
    "            print(\"Partial results saved to 'submit_format_partial.csv'. Exiting program.\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            for row in batch_data:\n",
    "                errors.append({\n",
    "                    \"ID\": row[\"Unnamed: 0\"],\n",
    "                    \"input\": row[\"input\"],\n",
    "                    \"response\": str(e),\n",
    "                    \"reason\": \"LLM invocation failed\"\n",
    "                })\n",
    "                predictions.append({\"ID\": row[\"Unnamed: 0\"], \"target\": random.choice([\"A\", \"B\", \"C\", \"D\"])})\n",
    "\n",
    "predictions = []\n",
    "errors = []\n",
    "count_requests = 0\n",
    "daily_limit = 1500\n",
    "batch_size = 1\n",
    "start_index = 145  # å¾žç¬¬49é¡Œé–‹å§‹ (ç´¢å¼•å¾ž0é–‹å§‹ï¼Œç¬¬49é¡Œæ˜¯48)\n",
    "\n",
    "# è®€å–ä¹‹å‰çš„é æ¸¬çµæžœ\n",
    "if os.path.exists(\"submit_format_partial.csv\"):\n",
    "    previous_df = pd.read_csv(\"submit_format_partial.csv\")\n",
    "    predictions = previous_df.to_dict(orient=\"records\")\n",
    "    count_requests = len(predictions)\n",
    "    print(f\"Loaded {count_requests} previous predictions from 'submit_format_partial.csv'.\")\n",
    "else:\n",
    "    print(\"No previous results found. Starting from scratch.\")\n",
    "\n",
    "for i in range(start_index, len(submit_df), batch_size):\n",
    "    batch_data = submit_df.iloc[i:i + batch_size].to_dict(orient=\"records\")\n",
    "    process_batch(batch_data, predictions, errors)\n",
    "    count_requests += len(batch_data)\n",
    "\n",
    "    if count_requests % 100 == 0:\n",
    "        print(f\"Processed {count_requests} requests...\")\n",
    "    \n",
    "    if count_requests >= daily_limit:\n",
    "        print(f\"Reached the daily limit of {daily_limit} requests. Stopping...\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)  \n",
    "\n",
    "output_df = pd.DataFrame(predictions)\n",
    "output_df.to_csv(\"submit_format.csv\", index=False)\n",
    "\n",
    "print(\"Results saved to submit_format.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
